name: TransAttentionHeadsKernel
stationary: false
params: []

doc: |
    The transformer's transformer_attention_heads kernel.

value: |
    if(x1 != x2) {
        return 0.82;
    }
    else {
        return 1;
    }

grad:
    x1: |
        return 0.0;

    x2: |
        return 0.0;
