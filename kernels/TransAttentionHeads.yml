name: TransAttentionHeadsKernel
stationary: false
params: []

doc: |
    The transformer's transformer_attention_heads kernel.

value: |
    if(x1 != x2) {
        return 0.85;
    }
    else {
        if(x1 == 0) {
            return 0.85;
        }
        else if(x1 == 1) {
            return 0.9;
        }
    }

grad:
    x1: |
        return 0.0;

    x2: |
        return 0.0;
